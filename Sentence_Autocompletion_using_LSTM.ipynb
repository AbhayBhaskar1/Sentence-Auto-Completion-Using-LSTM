{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkjESSE7ZnvY"
      },
      "source": [
        "# LSTM Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK1htKtgZnvc"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVbW4eKYZnvd",
        "outputId": "517c5f66-0f08-4325-bc5d-89de31327c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import nltk\n",
        "import regex as re\n",
        "!pip install --upgrade keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kb2dMsRZnve",
        "outputId": "c19601ec-f5c7-467a-f81e-eb25fb8026b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "holme.txt\n"
          ]
        }
      ],
      "source": [
        "input_file = 'holme.txt'\n",
        "print(input_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BYj65K4KZnvf"
      },
      "outputs": [],
      "source": [
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    data = infile.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00RN0NquZnvf",
        "outputId": "731e92a3-9216-4b4f-ebc1-5a832b9339e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"*Project Gutenberg's Etext of Tom Swift And His Submarine Boat*\\n\\n#4 in the Victor Appleton's Tom Swi\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100] # view first few characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DSGT_UbhZnvg"
      },
      "outputs": [],
      "source": [
        "# Limit data to 500000 characters\n",
        "data = data[:500000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njBkknORZnvg"
      },
      "source": [
        "# Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WanazdLXZnvg"
      },
      "outputs": [],
      "source": [
        "# Function to remove emojis and special characters from text\n",
        "def remove_emojis_and_special_characters(text):\n",
        "    # Remove emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Bl5gX2aAZnvh"
      },
      "outputs": [],
      "source": [
        "# Preprocessing pipeline\n",
        "def preprocess_pipeline(data) -> 'list':\n",
        "    # Split by newline character\n",
        "    sentences = data.split('\\n')\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = remove_emojis_and_special_characters(sentences[i])\n",
        "    # Remove leading and trailing spaces\n",
        "    sentences = [s.strip() for s in sentences]\n",
        "    # Drop empty sentences\n",
        "    sentences = [s for s in sentences if len(s) > 0]\n",
        "    # Tokenization\n",
        "    tokenized = []\n",
        "    for sentence in sentences:\n",
        "        # Convert to lowercase\n",
        "        sentence = sentence.lower()\n",
        "        tokenized.append(sentence)\n",
        "    return tokenized\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = preprocess_pipeline(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KjSa3bwZZnvh"
      },
      "outputs": [],
      "source": [
        "# Tokenize words\n",
        "tokenizer = Tokenizer(oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(tokenized_sentences)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "tokenizer.word_counts\n",
        "tokenizer.word_index\n",
        "\n",
        "# Generate input sequences\n",
        "input_sequences = []\n",
        "for line in tokenized_sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i + 1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W3u9STPxZnvi"
      },
      "outputs": [],
      "source": [
        "# Creates labels with input sequences\n",
        "X,labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-11T05:32:13.168190Z",
          "iopub.status.busy": "2024-04-11T05:32:13.167751Z",
          "iopub.status.idle": "2024-04-11T05:32:20.041506Z",
          "shell.execute_reply": "2024-04-11T05:32:20.040383Z",
          "shell.execute_reply.started": "2024-04-11T05:32:13.168137Z"
        },
        "id": "PV7PePT-Znvi"
      },
      "outputs": [],
      "source": [
        "# Split data into training, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_temp, X_val_test, y_train_temp, y_val_test = train_test_split(X, ys, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukk4W4vCZnvi"
      },
      "source": [
        "# Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-11T06:50:19.346868Z",
          "iopub.status.busy": "2024-04-11T06:50:19.345839Z",
          "iopub.status.idle": "2024-04-11T07:17:23.071736Z",
          "shell.execute_reply": "2024-04-11T07:17:23.070573Z",
          "shell.execute_reply.started": "2024-04-11T06:50:19.346830Z"
        },
        "id": "PlcBC3gUZnvi"
      },
      "outputs": [],
      "source": [
        "# Define your model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_temp, y_train_temp, epochs=50, validation_data=(X_val, y_val), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEYixvG_Znvj"
      },
      "source": [
        "# Save Models (Weights and biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-11T07:17:23.074643Z",
          "iopub.status.busy": "2024-04-11T07:17:23.074319Z",
          "iopub.status.idle": "2024-04-11T07:17:23.216893Z",
          "shell.execute_reply": "2024-04-11T07:17:23.215911Z",
          "shell.execute_reply.started": "2024-04-11T07:17:23.074617Z"
        },
        "id": "px0JQk1DZnvj"
      },
      "outputs": [],
      "source": [
        "# Save model architecture as JSON file\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"lstm_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L_BwDAwZnvj",
        "outputId": "500ded42-ab18-4698-c199-85d71e9a78c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture loaded successfully from JSON file.\n"
          ]
        }
      ],
      "source": [
        "# Load model architecture from JSON file\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "with open(\"lstm_model.json\", \"r\") as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "# Create model from loaded architecture\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "print(\"Model architecture loaded successfully from JSON file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-11T06:04:13.104775Z",
          "iopub.status.busy": "2024-04-11T06:04:13.104349Z",
          "iopub.status.idle": "2024-04-11T06:04:13.406339Z",
          "shell.execute_reply": "2024-04-11T06:04:13.404737Z",
          "shell.execute_reply.started": "2024-04-11T06:04:13.104743Z"
        },
        "id": "JGbX8cDlZnvk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "execution": {
          "iopub.execute_input": "2024-04-11T06:04:14.332289Z",
          "iopub.status.busy": "2024-04-11T06:04:14.331600Z",
          "iopub.status.idle": "2024-04-11T06:04:15.028083Z",
          "shell.execute_reply": "2024-04-11T06:04:15.026976Z",
          "shell.execute_reply.started": "2024-04-11T06:04:14.332254Z"
        },
        "id": "-2MCUTiNZnvk",
        "outputId": "05f75071-ffae-4e15-f676-44525ca39aaa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7430b57871e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Plot Loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om9KtDTfZnvk"
      },
      "source": [
        "# Inferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-11T06:15:08.096062Z",
          "iopub.status.busy": "2024-04-11T06:15:08.095068Z",
          "iopub.status.idle": "2024-04-11T06:15:08.103261Z",
          "shell.execute_reply": "2024-04-11T06:15:08.102149Z",
          "shell.execute_reply.started": "2024-04-11T06:15:08.096025Z"
        },
        "id": "egm1B-XuZnvk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_top_five_words(model, tokenizer, seed_text, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "\n",
        "    # Get the indices of the top five probabilities\n",
        "    top_five_indexes = np.argsort(predicted[0])[-5:][::-1]\n",
        "    top_five_words = []\n",
        "\n",
        "    for index in top_five_indexes:\n",
        "        for word, idx in tokenizer.word_index.items():\n",
        "            if idx == index:\n",
        "                top_five_words.append(word)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "execution": {
          "iopub.execute_input": "2024-04-11T07:21:37.822914Z",
          "iopub.status.busy": "2024-04-11T07:21:37.822420Z",
          "iopub.status.idle": "2024-04-11T07:21:38.082054Z",
          "shell.execute_reply": "2024-04-11T07:21:38.080961Z",
          "shell.execute_reply.started": "2024-04-11T07:21:37.822880Z"
        },
        "id": "HVMRNivXZnvl",
        "outputId": "630868bf-73bf-40be-f3f1-5e840558ef18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h1>Sentence AutoCompletion App With Five Outputs</h1><br><hr><ul><li>She is my caretaker</li><li>She is my pail</li><li>She is my wandered</li><li>She is my noon</li><li>She is my switches</li><li>She is my con</li><li>She is my deserved</li><li>She is my monster</li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_top_five_words(model, tokenizer, seed_text, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "\n",
        "    # Get the indices of the top five probabilities\n",
        "    top_five_indexes = np.argsort(predicted[0])[::-1][:10]\n",
        "    top_five_words = []\n",
        "\n",
        "    # Map indices back to words using tokenizer's word_index\n",
        "    for index in top_five_indexes:\n",
        "        for word, idx in tokenizer.word_index.items():\n",
        "            if idx == index:\n",
        "                top_five_words.append(word)\n",
        "                break\n",
        "\n",
        "    return top_five_words\n",
        "\n",
        "def predict_and_display_top_five_words(seed_text, model, tokenizer, max_sequence_len):\n",
        "    top_five_words = predict_top_five_words(model, tokenizer, seed_text, max_sequence_len)\n",
        "    heading_app = \"<h1>Sentence AutoCompletion App With Five Outputs</h1>\"\n",
        "    output_text = f\"<ul>{''.join([f'<li>{seed_text} {word}</li>' for word in top_five_words])}</ul>\"\n",
        "\n",
        "    return HTML(f\"{heading_app}<br><hr>{output_text}\")\n",
        "\n",
        "seed_text = \"She is my\"\n",
        "max_sequence_len = 20\n",
        "\n",
        "display(predict_and_display_top_five_words(seed_text, loaded_model, tokenizer, max_sequence_len))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "execution": {
          "iopub.execute_input": "2024-04-11T06:32:59.206205Z",
          "iopub.status.busy": "2024-04-11T06:32:59.205113Z",
          "iopub.status.idle": "2024-04-11T06:32:59.281620Z",
          "shell.execute_reply": "2024-04-11T06:32:59.280559Z",
          "shell.execute_reply.started": "2024-04-11T06:32:59.206146Z"
        },
        "id": "Wv8tayuAZnvm",
        "outputId": "e72ce699-7a1d-4164-e9c9-905e98c69aef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h1>Sentence AutoCompletion App With Five Outputs</h1><br><hr><ul><li>I have caretaker</li><li>I have pail</li><li>I have noon</li><li>I have monster</li><li>I have switches</li><li>I have wandered</li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test 2:\n",
        "seed_text = \"I have\"\n",
        "max_sequence_len = 20\n",
        "predict_and_display_top_five_words(seed_text, loaded_model, tokenizer, max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "execution": {
          "iopub.execute_input": "2024-04-11T07:23:00.192909Z",
          "iopub.status.busy": "2024-04-11T07:23:00.192508Z",
          "iopub.status.idle": "2024-04-11T07:23:00.270331Z",
          "shell.execute_reply": "2024-04-11T07:23:00.269254Z",
          "shell.execute_reply.started": "2024-04-11T07:23:00.192880Z"
        },
        "id": "RadQ7qZaZnvm",
        "outputId": "2a0b0e59-e92e-4744-b6ba-694c78ecb3dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h1>Sentence AutoCompletion App With Five Outputs</h1><br><hr><ul><li>We love pail</li><li>We love caretaker</li><li>We love noon</li><li>We love switches</li><li>We love wandered</li><li>We love monster</li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test 3:\n",
        "seed_text = \"We love\"\n",
        "max_sequence_len = 20\n",
        "predict_and_display_top_five_words(seed_text, loaded_model, tokenizer, max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "execution": {
          "iopub.execute_input": "2024-04-11T06:33:58.775637Z",
          "iopub.status.busy": "2024-04-11T06:33:58.775231Z",
          "iopub.status.idle": "2024-04-11T06:33:58.849540Z",
          "shell.execute_reply": "2024-04-11T06:33:58.848492Z",
          "shell.execute_reply.started": "2024-04-11T06:33:58.775606Z"
        },
        "id": "f6v4pQXBZnvm",
        "outputId": "4547e2ad-85c0-4541-d30a-7e4433230b6b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h1>Sentence AutoCompletion App With Five Outputs</h1><br><hr><ul><li>How are pail</li><li>How are switches</li><li>How are caretaker</li><li>How are wandered</li><li>How are noon</li><li>How are housekeeper</li><li>How are office</li></ul>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test 3:\n",
        "seed_text = \"How are\"\n",
        "max_sequence_len = 20\n",
        "predict_and_display_top_five_words(seed_text, loaded_model, tokenizer, max_sequence_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXO1ndWobQTP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4758440,
          "sourceId": 8065627,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4758543,
          "sourceId": 8065761,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4759977,
          "sourceId": 8067728,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
